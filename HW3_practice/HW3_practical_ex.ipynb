{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3: optimization of a CNN model\n",
    "The task of this homework is to optimize a CNN model for the CIFAR-100. You are free to define the architecture of the model, and the training procedure. The only contraints are:\n",
    "- It must be a `torch.nn.Module` object\n",
    "- The number of trained parameters must be less than 1 million\n",
    "- The test dataset must not be used for any step of training.\n",
    "- The final training notebook should run on Google Colab within a maximum 1 hour approximately.\n",
    "- Do not modify the random seed, as they are needed for reproducibility purpose.\n",
    "\n",
    "For the grading, you must use the `evaluate` function defined below. It takes a model as input, and returns the test accuracy as output.\n",
    "\n",
    "As a guideline, you are expected to **discuss** and motivate your choices regarding:\n",
    "- Model architecture\n",
    "- Hyperparameters (learning rate, batch size, etc)\n",
    "- Regularization methods\n",
    "- Optimizer\n",
    "- Validation scheme\n",
    "\n",
    "A code without any explanation of the choices will not be accepted. Test accuracy is not the only measure of success for this homework.\n",
    "\n",
    "Remember that most of the train process is randomized, store your model's weights after training and load it before the evaluation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "# Fix all random seeds\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# For full determinism\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Import the best device available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.mps.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "# load the data\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mCIFAR100(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtorchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mToTensor())\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate\u001b[39m(model):\n\u001b[1;32m      4\u001b[0m     params_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters())\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torchvision/datasets/cifar.py:66\u001b[0m, in \u001b[0;36mCIFAR10.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;241m=\u001b[39m train  \u001b[38;5;66;03m# training set or test set\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload()\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity():\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torchvision/datasets/cifar.py:137\u001b[0m, in \u001b[0;36mCIFAR10.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdownload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity():\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     download_and_extract_archive(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename, md5\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtgz_md5)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torchvision/datasets/cifar.py:132\u001b[0m, in \u001b[0;36mCIFAR10._check_integrity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename, md5 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_list \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_list:\n\u001b[1;32m    131\u001b[0m     fpath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_folder, filename)\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_integrity(fpath, md5):\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torchvision/datasets/utils.py:55\u001b[0m, in \u001b[0;36mcheck_integrity\u001b[0;34m(fpath, md5)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m md5 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_md5(fpath, md5)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torchvision/datasets/utils.py:47\u001b[0m, in \u001b[0;36mcheck_md5\u001b[0;34m(fpath, md5, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_md5\u001b[39m(fpath: Union[\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath], md5: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m md5 \u001b[38;5;241m==\u001b[39m calculate_md5(fpath, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torchvision/datasets/utils.py:42\u001b[0m, in \u001b[0;36mcalculate_md5\u001b[0;34m(fpath, chunk_size)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fpath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m chunk \u001b[38;5;241m:=\u001b[39m f\u001b[38;5;241m.\u001b[39mread(chunk_size):\n\u001b[0;32m---> 42\u001b[0m         md5\u001b[38;5;241m.\u001b[39mupdate(chunk)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m md5\u001b[38;5;241m.\u001b[39mhexdigest()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "def evaluate(model):\n",
    "    params_count = sum(p.numel() for p in model.parameters())\n",
    "    print('The model has {} parameters'.format(params_count))\n",
    "\n",
    "    if params_count > int(1e6):\n",
    "        print('The model has too many parameters! Not allowed to evaluate.')\n",
    "        return\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "    # print in bold red in a notebook\n",
    "    print('\\033[1m\\033[91mAccuracy on the test set: {}%\\033[0m'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of a simple CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:  556708\n"
     ]
    }
   ],
   "source": [
    "class TinyNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyNet, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = torch.nn.Linear(8*8*64, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.conv1(x))\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "        x = torch.nn.functional.relu(self.conv2(x))\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 8*8*64)\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "print(\"Model parameters: \", sum(p.numel() for p in TinyNet().parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of basic training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 4.6139\n",
      "Epoch [2/10], Loss: 4.5809\n",
      "Epoch [2/10], Loss: 4.5809\n",
      "Epoch [3/10], Loss: 4.5756\n",
      "Epoch [3/10], Loss: 4.5756\n",
      "Epoch [4/10], Loss: 4.5896\n",
      "Epoch [4/10], Loss: 4.5896\n",
      "Epoch [5/10], Loss: 4.5961\n",
      "Epoch [5/10], Loss: 4.5961\n",
      "Epoch [6/10], Loss: 4.5979\n",
      "Epoch [6/10], Loss: 4.5979\n",
      "Epoch [7/10], Loss: 4.6145\n",
      "Epoch [7/10], Loss: 4.6145\n",
      "Epoch [8/10], Loss: 4.5321\n",
      "Epoch [8/10], Loss: 4.5321\n",
      "Epoch [9/10], Loss: 4.5010\n",
      "Epoch [9/10], Loss: 4.5010\n",
      "Epoch [10/10], Loss: 4.3955\n",
      "Epoch [10/10], Loss: 4.3955\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = TinyNet()\n",
    "model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 10, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 556708 parameters\n",
      "\u001b[1m\u001b[91mAccuracy on the test set: 3.37%\u001b[0m\n",
      "\u001b[1m\u001b[91mAccuracy on the test set: 3.37%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# save the model on a file\n",
    "torch.save(model.state_dict(), 'tiny_net.pt')\n",
    "\n",
    "loaded_model = TinyNet()\n",
    "loaded_model.load_state_dict(torch.load('tiny_net.pt', weights_only=True))\n",
    "evaluate(loaded_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 45000\n",
      "Val samples:   5000\n",
      "Test samples:  10000\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 1) Data transforms\n",
    "# ------------------------------------------------------\n",
    "train_transform = T.Compose([\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = T.ToTensor()\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 2) Load full CIFAR-100 train set\n",
    "# ------------------------------------------------------\n",
    "full_train_dataset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=True, download=True, transform=train_transform\n",
    ")\n",
    "\n",
    "# Create validation split (10% of training data)\n",
    "val_size = int(0.1 * len(full_train_dataset))\n",
    "train_size = len(full_train_dataset) - val_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "# Validation must NOT use augmentation\n",
    "val_dataset.dataset.transform = test_transform\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=False, download=True, transform=test_transform\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3) DataLoaders\n",
    "# ------------------------------------------------------\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Val samples:   {len(val_dataset)}\")\n",
    "print(f\"Test samples:  {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 673508\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optional SE block (lightweight)\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=8):\n",
    "        super().__init__()\n",
    "        self.avg = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "class DWConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, use_se=False):\n",
    "        super().__init__()\n",
    "        self.use_se = use_se\n",
    "\n",
    "        self.depthwise = nn.Conv2d(\n",
    "            in_channels, in_channels, kernel_size=3,\n",
    "            stride=stride, padding=1, groups=in_channels, bias=False\n",
    "        )\n",
    "        self.pointwise = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size=1, bias=False\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        if use_se:\n",
    "            self.se = SEBlock(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        x = self.bn(x)\n",
    "        if self.use_se:\n",
    "            x = self.se(x)\n",
    "        return F.relu(x)\n",
    "\n",
    "class MobileNetTiny(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            DWConvBlock(32, 64, stride=1, use_se=True),\n",
    "            DWConvBlock(64, 128, stride=2, use_se=True),\n",
    "            DWConvBlock(128, 128, stride=1),\n",
    "            DWConvBlock(128, 256, stride=2, use_se=True),\n",
    "            DWConvBlock(256, 256, stride=1),\n",
    "            DWConvBlock(256, 512, stride=2, use_se=True),\n",
    "            DWConvBlock(512, 512, stride=1),\n",
    "        )\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(512, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "model = MobileNetTiny().to(device)\n",
    "print(\"Model parameters:\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 673508\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# 4) Your model (already defined)\n",
    "# ------------------------------------------------------\n",
    "\n",
    "model = MobileNetTiny().to(device)\n",
    "print(\"Model parameters:\", sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/50 | Loss: 3.8350 | Train Acc: 15.87% | Val Acc: 15.36%\n",
      "Epoch 002/50 | Loss: 3.0943 | Train Acc: 24.69% | Val Acc: 23.02%\n",
      "Epoch 002/50 | Loss: 3.0943 | Train Acc: 24.69% | Val Acc: 23.02%\n",
      "Epoch 003/50 | Loss: 2.7218 | Train Acc: 30.61% | Val Acc: 27.92%\n",
      "Epoch 003/50 | Loss: 2.7218 | Train Acc: 30.61% | Val Acc: 27.92%\n",
      "Epoch 004/50 | Loss: 2.4775 | Train Acc: 33.39% | Val Acc: 30.06%\n",
      "Epoch 004/50 | Loss: 2.4775 | Train Acc: 33.39% | Val Acc: 30.06%\n",
      "Epoch 005/50 | Loss: 2.3047 | Train Acc: 34.38% | Val Acc: 30.90%\n",
      "Epoch 005/50 | Loss: 2.3047 | Train Acc: 34.38% | Val Acc: 30.90%\n",
      "Epoch 006/50 | Loss: 2.1713 | Train Acc: 37.53% | Val Acc: 33.48%\n",
      "Epoch 006/50 | Loss: 2.1713 | Train Acc: 37.53% | Val Acc: 33.48%\n",
      "Epoch 007/50 | Loss: 2.0881 | Train Acc: 40.89% | Val Acc: 37.40%\n",
      "Epoch 007/50 | Loss: 2.0881 | Train Acc: 40.89% | Val Acc: 37.40%\n",
      "Epoch 008/50 | Loss: 2.0117 | Train Acc: 43.92% | Val Acc: 40.74%\n",
      "Epoch 008/50 | Loss: 2.0117 | Train Acc: 43.92% | Val Acc: 40.74%\n",
      "Epoch 009/50 | Loss: 1.9626 | Train Acc: 36.08% | Val Acc: 32.32%\n",
      "Epoch 009/50 | Loss: 1.9626 | Train Acc: 36.08% | Val Acc: 32.32%\n",
      "Epoch 010/50 | Loss: 1.9133 | Train Acc: 44.31% | Val Acc: 38.88%\n",
      "Epoch 010/50 | Loss: 1.9133 | Train Acc: 44.31% | Val Acc: 38.88%\n",
      "Epoch 011/50 | Loss: 1.8757 | Train Acc: 44.35% | Val Acc: 38.96%\n",
      "Epoch 011/50 | Loss: 1.8757 | Train Acc: 44.35% | Val Acc: 38.96%\n",
      "Epoch 012/50 | Loss: 1.8391 | Train Acc: 48.42% | Val Acc: 42.76%\n",
      "Epoch 012/50 | Loss: 1.8391 | Train Acc: 48.42% | Val Acc: 42.76%\n",
      "Epoch 013/50 | Loss: 1.8060 | Train Acc: 52.15% | Val Acc: 44.78%\n",
      "Epoch 013/50 | Loss: 1.8060 | Train Acc: 52.15% | Val Acc: 44.78%\n",
      "Epoch 014/50 | Loss: 1.7680 | Train Acc: 49.39% | Val Acc: 42.62%\n",
      "Epoch 014/50 | Loss: 1.7680 | Train Acc: 49.39% | Val Acc: 42.62%\n",
      "Epoch 015/50 | Loss: 1.7419 | Train Acc: 46.54% | Val Acc: 40.76%\n",
      "Epoch 015/50 | Loss: 1.7419 | Train Acc: 46.54% | Val Acc: 40.76%\n",
      "Epoch 016/50 | Loss: 1.7251 | Train Acc: 47.62% | Val Acc: 41.80%\n",
      "Epoch 016/50 | Loss: 1.7251 | Train Acc: 47.62% | Val Acc: 41.80%\n",
      "Epoch 017/50 | Loss: 1.6998 | Train Acc: 56.11% | Val Acc: 47.86%\n",
      "Epoch 017/50 | Loss: 1.6998 | Train Acc: 56.11% | Val Acc: 47.86%\n",
      "Epoch 018/50 | Loss: 1.6768 | Train Acc: 46.22% | Val Acc: 40.74%\n",
      "Epoch 018/50 | Loss: 1.6768 | Train Acc: 46.22% | Val Acc: 40.74%\n",
      "Epoch 019/50 | Loss: 1.6595 | Train Acc: 52.34% | Val Acc: 45.68%\n",
      "Epoch 019/50 | Loss: 1.6595 | Train Acc: 52.34% | Val Acc: 45.68%\n",
      "Epoch 020/50 | Loss: 1.6398 | Train Acc: 49.67% | Val Acc: 43.10%\n",
      "Epoch 020/50 | Loss: 1.6398 | Train Acc: 49.67% | Val Acc: 43.10%\n",
      "Epoch 021/50 | Loss: 1.6179 | Train Acc: 49.55% | Val Acc: 42.78%\n",
      "Epoch 021/50 | Loss: 1.6179 | Train Acc: 49.55% | Val Acc: 42.78%\n",
      "Epoch 022/50 | Loss: 1.6072 | Train Acc: 51.75% | Val Acc: 43.62%\n",
      "Epoch 022/50 | Loss: 1.6072 | Train Acc: 51.75% | Val Acc: 43.62%\n",
      "Epoch 023/50 | Loss: 1.5792 | Train Acc: 51.37% | Val Acc: 45.22%\n",
      "Epoch 023/50 | Loss: 1.5792 | Train Acc: 51.37% | Val Acc: 45.22%\n",
      "Epoch 024/50 | Loss: 1.5759 | Train Acc: 51.42% | Val Acc: 43.70%\n",
      "Epoch 024/50 | Loss: 1.5759 | Train Acc: 51.42% | Val Acc: 43.70%\n",
      "Epoch 025/50 | Loss: 1.5472 | Train Acc: 56.52% | Val Acc: 47.90%\n",
      "Epoch 025/50 | Loss: 1.5472 | Train Acc: 56.52% | Val Acc: 47.90%\n",
      "Epoch 026/50 | Loss: 1.5431 | Train Acc: 52.42% | Val Acc: 45.12%\n",
      "Epoch 026/50 | Loss: 1.5431 | Train Acc: 52.42% | Val Acc: 45.12%\n",
      "Epoch 027/50 | Loss: 1.5176 | Train Acc: 47.49% | Val Acc: 40.02%\n",
      "Epoch 027/50 | Loss: 1.5176 | Train Acc: 47.49% | Val Acc: 40.02%\n",
      "Epoch 028/50 | Loss: 1.5057 | Train Acc: 53.36% | Val Acc: 44.68%\n",
      "Epoch 028/50 | Loss: 1.5057 | Train Acc: 53.36% | Val Acc: 44.68%\n",
      "Epoch 029/50 | Loss: 1.4990 | Train Acc: 56.62% | Val Acc: 48.72%\n",
      "Epoch 029/50 | Loss: 1.4990 | Train Acc: 56.62% | Val Acc: 48.72%\n",
      "Epoch 030/50 | Loss: 1.4739 | Train Acc: 55.85% | Val Acc: 47.52%\n",
      "Epoch 030/50 | Loss: 1.4739 | Train Acc: 55.85% | Val Acc: 47.52%\n",
      "Epoch 031/50 | Loss: 1.4567 | Train Acc: 57.98% | Val Acc: 48.14%\n",
      "Epoch 031/50 | Loss: 1.4567 | Train Acc: 57.98% | Val Acc: 48.14%\n",
      "Epoch 032/50 | Loss: 1.4395 | Train Acc: 57.98% | Val Acc: 48.26%\n",
      "Epoch 032/50 | Loss: 1.4395 | Train Acc: 57.98% | Val Acc: 48.26%\n",
      "Epoch 033/50 | Loss: 1.4254 | Train Acc: 56.98% | Val Acc: 47.14%\n",
      "Epoch 033/50 | Loss: 1.4254 | Train Acc: 56.98% | Val Acc: 47.14%\n",
      "Epoch 034/50 | Loss: 1.4061 | Train Acc: 60.20% | Val Acc: 48.42%\n",
      "Epoch 034/50 | Loss: 1.4061 | Train Acc: 60.20% | Val Acc: 48.42%\n",
      "Epoch 035/50 | Loss: 1.3922 | Train Acc: 54.63% | Val Acc: 43.40%\n",
      "Epoch 035/50 | Loss: 1.3922 | Train Acc: 54.63% | Val Acc: 43.40%\n",
      "Epoch 036/50 | Loss: 1.3718 | Train Acc: 59.29% | Val Acc: 48.84%\n",
      "Epoch 036/50 | Loss: 1.3718 | Train Acc: 59.29% | Val Acc: 48.84%\n",
      "Epoch 037/50 | Loss: 1.3585 | Train Acc: 56.94% | Val Acc: 48.10%\n",
      "Epoch 037/50 | Loss: 1.3585 | Train Acc: 56.94% | Val Acc: 48.10%\n",
      "Epoch 038/50 | Loss: 1.3456 | Train Acc: 61.14% | Val Acc: 48.90%\n",
      "Epoch 038/50 | Loss: 1.3456 | Train Acc: 61.14% | Val Acc: 48.90%\n",
      "Epoch 039/50 | Loss: 1.3350 | Train Acc: 60.26% | Val Acc: 48.62%\n",
      "Epoch 039/50 | Loss: 1.3350 | Train Acc: 60.26% | Val Acc: 48.62%\n",
      "Epoch 040/50 | Loss: 1.3085 | Train Acc: 61.36% | Val Acc: 49.42%\n",
      "Epoch 040/50 | Loss: 1.3085 | Train Acc: 61.36% | Val Acc: 49.42%\n",
      "Epoch 041/50 | Loss: 1.2902 | Train Acc: 61.01% | Val Acc: 50.06%\n",
      "Epoch 041/50 | Loss: 1.2902 | Train Acc: 61.01% | Val Acc: 50.06%\n",
      "Epoch 042/50 | Loss: 1.2632 | Train Acc: 63.28% | Val Acc: 50.40%\n",
      "Epoch 042/50 | Loss: 1.2632 | Train Acc: 63.28% | Val Acc: 50.40%\n",
      "Epoch 043/50 | Loss: 1.2596 | Train Acc: 64.16% | Val Acc: 53.28%\n",
      "Epoch 043/50 | Loss: 1.2596 | Train Acc: 64.16% | Val Acc: 53.28%\n",
      "Epoch 044/50 | Loss: 1.2186 | Train Acc: 67.00% | Val Acc: 52.94%\n",
      "Epoch 044/50 | Loss: 1.2186 | Train Acc: 67.00% | Val Acc: 52.94%\n",
      "Epoch 045/50 | Loss: 1.2053 | Train Acc: 66.65% | Val Acc: 52.76%\n",
      "Epoch 045/50 | Loss: 1.2053 | Train Acc: 66.65% | Val Acc: 52.76%\n",
      "Epoch 046/50 | Loss: 1.1931 | Train Acc: 64.42% | Val Acc: 51.14%\n",
      "Epoch 046/50 | Loss: 1.1931 | Train Acc: 64.42% | Val Acc: 51.14%\n",
      "Epoch 047/50 | Loss: 1.1714 | Train Acc: 64.12% | Val Acc: 50.08%\n",
      "Epoch 047/50 | Loss: 1.1714 | Train Acc: 64.12% | Val Acc: 50.08%\n",
      "Epoch 048/50 | Loss: 1.1391 | Train Acc: 62.12% | Val Acc: 49.70%\n",
      "Epoch 048/50 | Loss: 1.1391 | Train Acc: 62.12% | Val Acc: 49.70%\n",
      "Epoch 049/50 | Loss: 1.1108 | Train Acc: 64.99% | Val Acc: 50.32%\n",
      "Epoch 049/50 | Loss: 1.1108 | Train Acc: 64.99% | Val Acc: 50.32%\n",
      "Epoch 050/50 | Loss: 1.0875 | Train Acc: 66.89% | Val Acc: 52.16%\n",
      "Epoch 050/50 | Loss: 1.0875 | Train Acc: 66.89% | Val Acc: 52.16%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 5) Helper function: compute accuracy\n",
    "# ------------------------------------------------------\n",
    "def compute_accuracy(loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            _, preds = torch.max(logits, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (preds == y).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 6) Training loop WITH train + val accuracy\n",
    "# ------------------------------------------------------\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # ---- Compute accuracies ----\n",
    "    train_acc = compute_accuracy(train_loader)\n",
    "    val_acc   = compute_accuracy(val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:03d}/{epochs} | \"\n",
    "          f\"Loss: {running_loss/len(train_loader):.4f} | \"\n",
    "          f\"Train Acc: {train_acc:.2f}% | \"\n",
    "          f\"Val Acc: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 673508 parameters\n",
      "\u001b[1m\u001b[91mAccuracy on the test set: 52.41%\u001b[0m\n",
      "\u001b[1m\u001b[91mAccuracy on the test set: 52.41%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Save weights and evaluate\n",
    "\n",
    "torch.save(model.state_dict(), \"mobilenet_tiny_cifar100.pth\")\n",
    "\n",
    "loaded_model = MobileNetTiny().to(device)\n",
    "loaded_model.load_state_dict(torch.load(\"mobilenet_tiny_cifar100.pth\", weights_only=True, map_location=device))\n",
    "\n",
    "evaluate(loaded_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
